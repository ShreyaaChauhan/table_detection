{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotations', 'info', 'categories', 'licenses', 'images']) keys\n",
      "73383 images\n",
      "95404 annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/TableBank/annotations/tablebank_word_train.json\") as json_file:\n",
    "    tablebank_word_train = json.load(json_file)\n",
    "    print(tablebank_word_train.keys(),'keys')\n",
    "    print(len(tablebank_word_train[\"images\"]),'images')\n",
    "    print(len(tablebank_word_train[\"annotations\"]),'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotations', 'info', 'categories', 'licenses', 'images']) keys\n",
      "2281 images\n",
      "2930 annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/TableBank/annotations/tablebank_word_test.json\") as json_file:\n",
    "    tablebank_word_test = json.load(json_file)\n",
    "    print(tablebank_word_test.keys(),'keys')\n",
    "    print(len(tablebank_word_test[\"images\"]),'images')\n",
    "    print(len(tablebank_word_test[\"annotations\"]),'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'images', 'categories', 'annotations']) keys\n",
      "5719 images\n",
      "7246 annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/TableBank/annotations/tablebank_latex_test.json\") as json_file:\n",
    "    tablebank_latex_test = json.load(json_file)\n",
    "    print(tablebank_latex_test.keys(),'keys')\n",
    "    print(len(tablebank_latex_test[\"images\"]),'images')\n",
    "    print(len(tablebank_latex_test[\"annotations\"]),'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'images', 'categories', 'annotations']) keys\n",
      "187199 images\n",
      "237431 annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/TableBank/annotations/tablebank_latex_train.json\") as json_file:\n",
    "    tablebank_latex_train = json.load(json_file)\n",
    "    print(tablebank_latex_train.keys(),'keys')\n",
    "    print(len(tablebank_latex_train[\"images\"]),'images')\n",
    "    print(len(tablebank_latex_train[\"annotations\"]),'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'categories', 'licenses', 'images', 'annotations']) keys\n",
      "2400 len-images\n",
      "240361 annotations\n",
      "2400 total images\n",
      "2400 len(id)\n",
      "4542 total annotations\n"
     ]
    }
   ],
   "source": [
    "with open('tablebank_both_train.json', 'w') as outfile:\n",
    "    data = {\n",
    "        \"info\" : tablebank_latex_train[\"info\"],\n",
    "        \"categories\": tablebank_latex_train[\"categories\"],\n",
    "        \"licenses\":  tablebank_latex_train[\"licenses\"], \n",
    "        \"images\": tablebank_latex_train[\"images\"][0:1200] + tablebank_word_test[\"images\"][0:1200],\n",
    "        \"annotations\": tablebank_latex_train[\"annotations\"] + tablebank_word_test[\"annotations\"],\n",
    "    }\n",
    "    #json.dump(data, outfile, indent = 4, sort_keys=True)\n",
    "    print(data.keys(),\"keys\")\n",
    "    print(len(data[\"images\"]),'len-images')\n",
    "    print(len(data[\"annotations\"]),'annotations')\n",
    "    images = data[\"images\"]\n",
    "    print(len(images), \"total images\")  \n",
    "    id = []\n",
    "    for info in images:\n",
    "        id.append(info[\"id\"])\n",
    "    print(len(id), \"len(id)\")\n",
    "    annotations = []\n",
    "    for datas in data[\"annotations\"]:\n",
    "        if datas[\"image_id\"] in id:\n",
    "            annotations.append(datas)\n",
    "    data[\"annotations\"] = annotations\n",
    "    print(len(annotations), \"total annotations\")\n",
    "    json.dump(data, outfile, indent = 4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'categories', 'licenses', 'images', 'annotations']) keys\n",
      "600 len-images\n",
      "10176 annotations\n",
      "600 total images\n",
      "600 len(id)\n",
      "800 total annotations\n"
     ]
    }
   ],
   "source": [
    "with open('tablebank_both_test.json', 'w') as outfile:\n",
    "    data = {\n",
    "        \"info\" : tablebank_latex_test[\"info\"],\n",
    "        \"categories\": tablebank_latex_test[\"categories\"],\n",
    "        \"licenses\":  tablebank_latex_test[\"licenses\"], \n",
    "        \"images\": tablebank_latex_test[\"images\"][0:300] + tablebank_word_test[\"images\"][0:300],\n",
    "        \"annotations\": tablebank_latex_test[\"annotations\"] + tablebank_word_test[\"annotations\"],\n",
    "    }\n",
    "    #json.dump(data, outfile, indent = 4, sort_keys=True)\n",
    "    print(data.keys(),\"keys\")\n",
    "    print(len(data[\"images\"]),'len-images')\n",
    "    print(len(data[\"annotations\"]),'annotations')\n",
    "    images = data[\"images\"]\n",
    "    print(len(images), \"total images\")  \n",
    "    id = []\n",
    "    for info in images:\n",
    "        id.append(info[\"id\"])\n",
    "    print(len(id), \"len(id)\")\n",
    "    annotations = []\n",
    "    for datas in data[\"annotations\"]:\n",
    "        if datas[\"image_id\"] in id:\n",
    "            annotations.append(datas)\n",
    "    data[\"annotations\"] = annotations\n",
    "    print(len(annotations), \"total annotations\")\n",
    "    json.dump(data, outfile, indent = 4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'categories', 'licenses', 'images', 'annotations']) keys\n",
      "2400 len-images\n",
      "4542 annotations\n",
      "4542\n",
      "4542\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"tablebank_both_train.json\") as json_file:\n",
    "    tablebank_both_train = json.load(json_file)\n",
    "with open(\"tablebank_both_train_new.json\", 'w') as json_file: \n",
    "    data = {\n",
    "        \"info\" : tablebank_both_train[\"info\"],\n",
    "        \"categories\": tablebank_both_train[\"categories\"],\n",
    "        \"licenses\":  tablebank_both_train[\"licenses\"], \n",
    "        \"images\": tablebank_both_train[\"images\"] ,\n",
    "        \"annotations\": tablebank_both_train[\"annotations\"] ,\n",
    "    }\n",
    "    print(data.keys(),\"keys\")\n",
    "    print(len(data[\"images\"]),'len-images')\n",
    "    print(len(data[\"annotations\"]),'annotations')\n",
    "    images = data[\"images\"]\n",
    "    ids = []\n",
    "    count = 1\n",
    "    annotations = []\n",
    "    for info in data[\"annotations\"]:\n",
    "        info[\"id\"] =  count\n",
    "        annotations.append(info)\n",
    "        count +=1\n",
    "    data[\"annotations\"] = annotations\n",
    "    for info in data[\"annotations\"]:\n",
    "        ids.append(info[\"id\"])\n",
    "    print(len(ids))\n",
    "    print(len(set(ids)))\n",
    "    json.dump(data, json_file, indent = 4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'categories', 'licenses', 'images', 'annotations']) keys\n",
      "600 len-images\n",
      "800 annotations\n",
      "800\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"tablebank_both_test.json\") as json_file:\n",
    "    tablebank_both_test = json.load(json_file)\n",
    "with open(\"tablebank_both_test_new.json\", 'w') as json_file: \n",
    "    data = {\n",
    "        \"info\" : tablebank_both_test[\"info\"],\n",
    "        \"categories\": tablebank_both_test[\"categories\"],\n",
    "        \"licenses\":  tablebank_both_test[\"licenses\"], \n",
    "        \"images\": tablebank_both_test[\"images\"] ,\n",
    "        \"annotations\": tablebank_both_test[\"annotations\"] ,\n",
    "    }\n",
    "    print(data.keys(),\"keys\")\n",
    "    print(len(data[\"images\"]),'len-images')\n",
    "    print(len(data[\"annotations\"]),'annotations')\n",
    "    images = data[\"images\"]\n",
    "    ids = []\n",
    "    count = 1\n",
    "    annotations = []\n",
    "    for info in data[\"annotations\"]:\n",
    "        info[\"id\"] =  count\n",
    "        annotations.append(info)\n",
    "        count +=1\n",
    "    data[\"annotations\"] = annotations\n",
    "    for info in data[\"annotations\"]:\n",
    "        ids.append(info[\"id\"])\n",
    "    print(len(ids))\n",
    "    print(len(set(ids)))\n",
    "    json.dump(data, json_file, indent = 4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotations', 'categories', 'images', 'info', 'licenses']) keys\n",
      "2400 images\n",
      "4542 annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"tablebank_both_train.json\") as json_file:\n",
    "    tablebank_both_train = json.load(json_file)\n",
    "    print(tablebank_both_train.keys(),'keys')\n",
    "    print(len(tablebank_both_train[\"images\"]),'images')\n",
    "    print(len(tablebank_both_train[\"annotations\"]),'annotations')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shapely.geometry\n",
    "with open(\"data/GO-IIIT-5K/test.json\") as json_file:\n",
    "    GO_IIIT_5K_test= json.load(json_file)\n",
    "    data = {\n",
    "        \"categories\": GO_IIIT_5K_test[\"categories\"],\n",
    "        \"images\": GO_IIIT_5K_test[\"images\"] ,\n",
    "        \"annotations\": GO_IIIT_5K_test[\"annotations\"] ,\n",
    "    }\n",
    "    #convert bounding boxes to polygons\n",
    "    for i in data[\"annotations\"]:\n",
    "        #Only the segmentations that are bounding boxes\n",
    "        bbox=tuple(i[\"bbox\"])\n",
    "        #Retrieve polygon from bbox through shapely.geometry.box, format was \n",
    "        polygon=shapely.geometry.box(*(bbox[0],bbox[1],bbox[0]+bbox[2], bbox[1]+bbox[3]), ccw=True)\n",
    "        K=str(polygon.wkt).split(\"POLYGON ((\")[-1].split(\"))\")[0].split(',')\n",
    "        polygon=[]\n",
    "        for m in K:\n",
    "            for p in m.split(\" \"):\n",
    "                if p:\n",
    "                    polygon.append(int(p))\n",
    "        polygon=[polygon]\n",
    "        data['segmentation'] = []\n",
    "        data['segmentation'] = polygon\n",
    "        #print(data[\"segmentation\"])\n",
    "    print(data[\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry\n",
    "\n",
    "#convert bounding boxes to polygons\n",
    "for i in d[\"annotations\"]:\n",
    "  #Only the segmentations that are bounding boxes\n",
    "  if i[\"segmentation\"] == None:\n",
    "    bbox=tuple(i[\"bbox\"])\n",
    "    print(i[\"bbox\"])\n",
    "    #Retrieve polygon from bbox through shapely.geometry.box, format was \n",
    "    polygon=shapely.geometry.box(*(bbox[0],bbox[1],bbox[0]+bbox[2], bbox[1]+bbox[3]), ccw=True)    ))\n",
    "    #Retrieve polygon from bbox through shapely.geometry.box, format was \n",
    "    polygon=shapely.geometry.box(*(bbox[0],bbox[1],bbox[0]+bbox[2], bbox[1]+bbox[3]), ccw=True)    ))\n",
    "    K=str(polygon.wkt).split(\"POLYGON ((\")[-1].split(\"))\")[0].split(',')\n",
    "    polygon=[]\n",
    "    for m in K:\n",
    "      for p in m.split(\" \"):\n",
    "        if p:\n",
    "          polygon.append(int(p))\n",
    "\n",
    "    polygon=[polygon]\n",
    "    print(polygon)\n",
    "\n",
    "    i[\"segmentation\"] = polygon\n",
    "\n",
    "#Resulting in proper polygons:\n",
    "[4063, 2452, 474, 207]\n",
    "[[4537, 2452, 4537, 2659, 4063, 2659, 4063, 2452, 4537, 2452]]\n",
    "[3268, 1553, 395, 288]\n",
    "[[3663, 1553, 3663, 1841, 3268, 1841, 3268, 1553, 3663, 1553]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotations', 'categories', 'images']) keys\n",
      "9333 images\n",
      "11163 annotations\n",
      "11163\n",
      "11163\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/IIIT-AR-13K/train.json\") as json_file:\n",
    "    test = json.load(json_file)\n",
    "    print(test.keys(),'keys')\n",
    "    print(len(test[\"images\"]),'images')\n",
    "    print(len(test[\"annotations\"]),'annotations')\n",
    "    data = {\n",
    "        \"categories\": test[\"categories\"],\n",
    "        \"images\": test[\"images\"] ,\n",
    "        \"annotations\": test[\"annotations\"] ,\n",
    "    }\n",
    "    images = data[\"images\"]\n",
    "    ids = []\n",
    "    count = 1\n",
    "    annotations = []\n",
    "    for info in data[\"annotations\"]:\n",
    "        info[\"id\"] =  count\n",
    "        annotations.append(info)\n",
    "        count +=1\n",
    "    data[\"annotations\"] = annotations\n",
    "    for info in data[\"annotations\"]:\n",
    "        ids.append(info[\"id\"])\n",
    "    print(len(ids))\n",
    "    print(len(set(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9333\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory =\"data/IIIT-AR-13K/train\"\n",
    "lst = os.listdir(directory) # your directory path\n",
    "number_files = len(lst)\n",
    "print(number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotations', 'categories', 'images']) keys\n",
      "9333 images\n",
      "11163 annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "DATA = {}\n",
    "with open(\"data/iit_ar_13k/train.json\") as json_file:\n",
    "    test = json.load(json_file)\n",
    "    print(test.keys(),'keys')\n",
    "    print(len(test[\"images\"]),'images')\n",
    "    print(len(test[\"annotations\"]),'annotations')\n",
    "    data = {\n",
    "        \"images\": test[\"images\"][0:2400],\n",
    "        \"annotations\": test[\"annotations\"] ,\n",
    "        \"categories\": test[\"categories\"] ,\n",
    "    }\n",
    "    DATA = data\n",
    "    \n",
    "with open(\"train.json\", 'w') as output_file:\n",
    "    #json.dump(DATA, output_file, indent = 4)\n",
    "    \n",
    "    images = data[\"images\"]\n",
    "    ids = []\n",
    "    count = 1\n",
    "    annotations = []\n",
    "    for info in data[\"annotations\"]:\n",
    "        info[\"id\"] =  count\n",
    "        annotations.append(info)\n",
    "        count +=1\n",
    "    data[\"annotations\"] = annotations\n",
    "    for info in data[\"annotations\"]:\n",
    "        ids.append(info[\"id\"])\n",
    "    print(len(ids))\n",
    "    print(len(set(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'annotations', 'categories']) keys\n",
      "600 len-images\n",
      "2596 annotations\n",
      "600 total images\n",
      "600 len(id)\n",
      "2256 total annotations\n"
     ]
    }
   ],
   "source": [
    "DATA = {}\n",
    "with open(\"data/dummy/test.json\") as json_file:\n",
    "    train = json.load(json_file)\n",
    "with open('test.json', 'w') as outfile:\n",
    "    data = {\n",
    "        \"images\": train[\"images\"][0:600] ,\n",
    "        \"annotations\": train[\"annotations\"] ,\n",
    "        \"categories\": train[\"categories\"],\n",
    "    }\n",
    "    #json.dump(data, outfile, indent = 4, sort_keys=True)\n",
    "    print(data.keys(),\"keys\")\n",
    "    print(len(data[\"images\"]),'len-images')\n",
    "    print(len(data[\"annotations\"]),'annotations')\n",
    "    images = data[\"images\"]\n",
    "    print(len(images), \"total images\")  \n",
    "    id = []\n",
    "    for info in images:\n",
    "        id.append(info[\"id\"])\n",
    "    print(len(id), \"len(id)\")\n",
    "    annotations = []\n",
    "    for datas in data[\"annotations\"]:\n",
    "        if datas[\"image_id\"] in id:\n",
    "            annotations.append(datas)\n",
    "    data[\"annotations\"] = annotations\n",
    "    print(len(annotations), \"total annotations\")\n",
    "    json.dump(data, outfile, indent = 4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''# Python program to explain cv2.rectangle() method \n",
    "   \n",
    "# importing cv2 \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "# path \n",
    "path = \"/Users/shreyachauhan/Downloads/GO-IIIT-5K/annual_report_table_test_jpg/AR_1079.jpg\"\n",
    "# Reading an image in default mode\n",
    "image = cv2.imread(path)\n",
    "   \n",
    "# Window name in which image is displayed\n",
    "window_name = 'Image'\n",
    "  \n",
    "# Start coordinate, here (5, 5)\n",
    "# represents the top left corner of rectangle\n",
    "start_point = (5, 5)\n",
    "  \n",
    "# Ending coordinate, here (220, 220)\n",
    "# represents the bottom right corner of rectangle\n",
    "end_point = (220, 220)\n",
    "  \n",
    "# Blue color in BGR\n",
    "color = (255, 0, 0)\n",
    "  \n",
    "# Line thickness of 2 px\n",
    "thickness = 2\n",
    "  \n",
    "# Using cv2.rectangle() method\n",
    "# Draw a rectangle with blue line borders of thickness of 2 px\n",
    "image = cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "  \n",
    "# Displaying the image \n",
    "cv2.imshow(window_name, image) \n",
    "#cv2.imshow(' ',image)\n",
    "#plt.show()\n",
    "\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "path = \"/Users/shreyachauhan/Downloads/GO-IIIT-5K/GO-IIIT-5K/test/AR_3809.jpg\"\n",
    "img=cv2.imread(path,1) #load the image\n",
    "\n",
    "bbox_1 = [182,\n",
    "                702,\n",
    "                830,\n",
    "                809]\n",
    "bbox_2 = [76, 984, 750, 1080]\n",
    "\n",
    "# Blue color in BGR\n",
    "color = (255, 0, 0)\n",
    "  \n",
    "# Line thickness of 2 px\n",
    "thickness = 2\n",
    "\n",
    "[x,y,w,h] = bbox_1\n",
    "cv2.rectangle(img, (int(x), int(y)), (int(w), int(h)), color, 2)\n",
    "\n",
    "'''c1, c2 = (int(coor[1]), int(coor[0])), (int(coor[3]), int(coor[2]))\n",
    "Line 159 -> cv2.rectangle(image, c1, (int(np.float32(c3[0])), int(np.float32(c3[1]))), bbox_color, -1)'''\n",
    "\n",
    "cv2.imshow(\"mycastle\", img)\n",
    "cv2.imwrite(\"myNewCastle.jpg\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "path = \"data/trackA_modern/train/cTDaR_t10001.jpg\"\n",
    "img=cv2.imread(path,1) #load the image\n",
    "bbox =[\n",
    "                44,\n",
    "                175,\n",
    "                706,\n",
    "                98\n",
    "            ]\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "[x,y,w,h] = bbox\n",
    "cv2.rectangle(img, (int(x), int(y)), (int(w), int(h)), color, 2)\n",
    "cv2.imwrite(\"myNewCastle.jpg\", img)\n",
    "#cv2.imshow(\"mycastle\", img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
